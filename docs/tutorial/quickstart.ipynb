{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HybridBackend Quickstart\n",
    "\n",
    "In this tutorial, we use [HybridBackend](https://hybridbackend.readthedocs.io/en/latest/)\n",
    "to speed up training of a sample ranking model based on stacked \n",
    "[DCNv2](https://arxiv.org/abs/2008.13535) on \n",
    "[Taobao ad click datasets](https://tianchi.aliyun.com/dataset/dataDetail?dataId=56)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why HybridBackend\n",
    "\n",
    "\n",
    "- Training industrial recommendation models can benefit greatly from GPUs\n",
    "\n",
    "  - Embedding layer becomes wider, consuming up to thousands of feature fields,\n",
    "  which requires larger memory bandwidth;\n",
    "  - Feature interaction layer is going deeper by leveraging multiple DNN\n",
    "  submodules over different subsets of features, which requires higher computing\n",
    "  capability;\n",
    "  - GPUs provide much higher computing capability, larger memory bandwidth, and\n",
    "  faster data movement;\n",
    "\n",
    "- Industrial recommendation models do not take full advantage of the GPU\n",
    "  resources by canonical training frameworks\n",
    "\n",
    "  - Industrial recommendation models contain up to a thousand of input\n",
    "  feature fields, introducing fragmentary and memory-intensive operations;\n",
    "  - The multiple constituent feature interaction submodules introduce\n",
    "  substantial small-sized compute kernels;\n",
    "\n",
    "- Training framework of industrial recommendation models must be less-invasive\n",
    "   and compatible with existing workflow\n",
    "\n",
    "  - Training is only a part of production recommendation system, it needs great\n",
    "  effort to modify inference pipeline;\n",
    "  - AI scientists write models in a variety of ways, especially in a big team.\n",
    "\n",
    "HybridBackend enables speeding up of training industrial recommendation models\n",
    "on GPUs with minimum effort. In this tutorial, you will learn how to use\n",
    "HybridBackend to make training of industrial recommendation models much faster.\n",
    "\n",
    "See [HybridBackend GitHub repo](https://github.com/alibaba/HybridBackend) and\n",
    "[the paper](https://ieeexplore.ieee.org/document/9835450) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "- Hardware\n",
    "  - Modern GPU and interconnect (e.g. A10 / PCIe Gen4)\n",
    "  - Fast data storage (e.g. ESSD)\n",
    "- Software\n",
    "  - Ubuntu 20.04 or above\n",
    "  - Python 3.8 or above\n",
    "  - CUDA 11.4\n",
    "  - TensorFlow 1.15\n",
    "- [Taobao Ad Click Dataset](https://tianchi.aliyun.com/dataset/dataDetail?dataId=56)\n",
    "  - TFRecord Format\n",
    "  - Parquet Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install hybridbackend-tf115-cu114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample ranking model\n",
    "\n",
    "In this tutorial, a sample ranking model based on stacked \n",
    "[DCNv2](https://arxiv.org/abs/2008.13535) is used. \n",
    "You can see code in `ranking` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import module_wrapper as deprecation\n",
    "deprecation._PER_MODULE_WARNING_LIMIT = 0\n",
    "tf.get_logger().propagate = False\n",
    "\n",
    "from ranking.data import DataSpec\n",
    "from ranking.model import stacked_dcn_v2\n",
    "\n",
    "\n",
    "# Global configuration\n",
    "train_max_steps = 100\n",
    "train_batch_size = 16000\n",
    "data_spec = DataSpec.read('ranking/taobao/data/spec.json')\n",
    "\n",
    "\n",
    "def train(iterator, embedding_weight_device, dnn_device):\n",
    "  batch = iterator.get_next()\n",
    "  batch.pop('ts')\n",
    "  labels = tf.reshape(tf.to_float(batch.pop('label')), shape=[-1, 1])\n",
    "  features = []\n",
    "  for f in batch:\n",
    "    feature = batch[f]\n",
    "    if data_spec.embedding_dims[f] is None:\n",
    "      features.append(data_spec.transform_numeric(f, feature))\n",
    "    else:\n",
    "      with tf.device(embedding_weight_device):\n",
    "        embedding_weights = tf.get_variable(\n",
    "          f'{f}_weight',\n",
    "          shape=(data_spec.embedding_sizes[f], data_spec.embedding_dims[f]),\n",
    "          initializer=tf.random_uniform_initializer(-1e-3, 1e-3))\n",
    "      features.append(\n",
    "        data_spec.transform_categorical(f, feature, embedding_weights))\n",
    "\n",
    "  with tf.device(dnn_device):\n",
    "    logits = stacked_dcn_v2(\n",
    "      features,\n",
    "      [1024, 1024, 512, 256, 1])\n",
    "    loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(labels, logits))\n",
    "    step = tf.train.get_or_create_global_step()\n",
    "    opt = tf.train.AdagradOptimizer(learning_rate=0.001)\n",
    "    train_op = opt.minimize(loss, global_step=step)\n",
    "\n",
    "  hooks = []\n",
    "  hooks.append(tf.train.StepCounterHook(10))\n",
    "  hooks.append(tf.train.StopAtStepHook(train_max_steps))\n",
    "  config = tf.ConfigProto(allow_soft_placement=True)\n",
    "  config.gpu_options.allow_growth = True\n",
    "  config.gpu_options.force_gpu_compatible = True\n",
    "  with tf.train.MonitoredTrainingSession(\n",
    "      '', hooks=hooks, config=config) as sess:\n",
    "    while not sess.should_stop():\n",
    "      sess.run(train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training without HybridBackend\n",
    "\n",
    "Without HybridBackend, training the sample ranking model underutilizes GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Download training data in TFRecord format\n",
    "!wget http://easyrec.oss-cn-beijing.aliyuncs.com/data/taobao/day_0.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "  ds = tf.data.TFRecordDataset('./day_0.tfrecord', compression_type='GZIP')\n",
    "  ds = ds.batch(train_batch_size, drop_remainder=True)\n",
    "  ds = ds.map(\n",
    "    lambda batch: tf.io.parse_example(batch, data_spec.to_example_spec()))\n",
    "  ds = ds.prefetch(2)\n",
    "  iterator = tf.data.make_one_shot_iterator(ds)\n",
    "\n",
    "  with tf.device('/gpu:0'):\n",
    "    train(iterator, '/cpu:0', '/gpu:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with HybridBackend\n",
    "\n",
    "By just one-line importing, HybridBackend uses packing and interleaving to\n",
    "speed up embedding layers dramatically and automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Note: Once HybridBackend is on, you need to restart notebook to turn it off.\n",
    "import hybridbackend.tensorflow as hb\n",
    "\n",
    "# Exact same code except HybridBackend is on.\n",
    "with tf.Graph().as_default():\n",
    "  ds = tf.data.TFRecordDataset('./day_0.tfrecord', compression_type='GZIP')\n",
    "  ds = ds.batch(train_batch_size, drop_remainder=True)\n",
    "  ds = ds.map(\n",
    "    lambda batch: tf.io.parse_example(batch, data_spec.to_example_spec()))\n",
    "  ds = ds.prefetch(2)\n",
    "  iterator = tf.data.make_one_shot_iterator(ds)\n",
    "\n",
    "  with tf.device('/gpu:0'):\n",
    "    train(iterator, '/cpu:0', '/gpu:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with HybridBackend (Optimized data pipeline)\n",
    "\n",
    "Even greater training performance gains can be archived if we use optimized\n",
    "data pipeline provided by HybridBackend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Download training data in Parquet format\n",
    "!wget http://easyrec.oss-cn-beijing.aliyuncs.com/data/taobao/day_0.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Note: Once HybridBackend is on, you need to restart notebook to turn it off.\n",
    "import hybridbackend.tensorflow as hb\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "  ds = hb.data.Dataset.from_parquet('./day_0.parquet')\n",
    "  ds = ds.batch(train_batch_size, drop_remainder=True)\n",
    "  ds = ds.prefetch(2)\n",
    "  iterator = tf.data.make_one_shot_iterator(ds)\n",
    "\n",
    "  with tf.device('/gpu:0'):\n",
    "    train(iterator, '/cpu:0', '/gpu:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11325ad6ff2151702fdf2e630d373c9c1132c4b70289fb211a76d62cc32462df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
